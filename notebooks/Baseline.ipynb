{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849c8a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1322a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "K = 10\n",
    "N_BOOT = 20       \n",
    "NEG_RATIO = 1.0\n",
    "ALPHA_DECAY = 0.01\n",
    "TIME_WINDOW = 30\n",
    "SAMPLE_USERS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78bdaba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(r, k):\n",
    "    r = np.array(r)[:k]\n",
    "    dcg = np.sum((2**r - 1) / np.log2(np.arange(2, len(r) + 2)))\n",
    "    ideal_r = np.sort(r)[::-1]\n",
    "    idcg = np.sum((2**ideal_r - 1) / np.log2(np.arange(2, len(ideal_r) + 2)))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def apk(actual, predicted, k):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    return score / min(len(actual), k) if actual else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84f24d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_negative_samples(df, all_items, negative_ratio=1.0, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rows = []\n",
    "    for u, grp in df.groupby(\"user_id\"):\n",
    "        pos_items = set(grp[grp[\"rating\"] > 0][\"item_id\"])\n",
    "        n_neg = int(len(pos_items) * negative_ratio)\n",
    "        if n_neg > 0:\n",
    "            neg_items = rng.choice(list(set(all_items) - pos_items), size=n_neg, replace=False)\n",
    "            for i in neg_items:\n",
    "                rows.append({\"user_id\": u, \"item_id\": i, \"rating\": 0})\n",
    "    neg_df = pd.DataFrame(rows)\n",
    "    return pd.concat([df, neg_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a226d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_recommender(items, k=10, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return lambda users: {u: rng.choice(items, size=k, replace=False).tolist() for u in users}\n",
    "\n",
    "def make_popular_recommender(train_df, k=10):\n",
    "    top_items = train_df[train_df[\"rating\"]>0][\"item_id\"].value_counts().index[:k].tolist()\n",
    "    return lambda users: {u: top_items for u in users}\n",
    "\n",
    "def make_popular_time_recommender(train_df, k=10, alpha=0.01):\n",
    "    now = train_df[\"timestamp\"].max()\n",
    "    train_df[\"weight\"] = train_df[\"rating\"] * np.exp(-alpha * (now - train_df[\"timestamp\"]).dt.days)\n",
    "    top_items = train_df.groupby(\"item_id\")[\"weight\"].sum().sort_values(ascending=False).index[:k].tolist()\n",
    "    return lambda users: {u: top_items for u in users}\n",
    "\n",
    "def make_als_recommender(train_df, k=10, factors=32, reg=0.1, iters=15, seed=42):\n",
    "    users = train_df[\"user_id\"].unique()\n",
    "    items = train_df[\"item_id\"].unique()\n",
    "    user_to_idx = {u:i for i,u in enumerate(users)}\n",
    "    idx_to_item = {i:u for u,i in enumerate({item:i for i,item in enumerate(items)})}\n",
    "\n",
    "    row = train_df[\"user_id\"].map(user_to_idx)\n",
    "    col = train_df[\"item_id\"].map({i:j for j,i in enumerate(items)})\n",
    "    data_vals = train_df[\"rating\"]\n",
    "    user_item_csr = csr_matrix((data_vals, (row, col)), shape=(len(users), len(items)))\n",
    "\n",
    "    model = AlternatingLeastSquares(factors=factors, regularization=reg, iterations=iters, random_state=seed)\n",
    "    model.fit(user_item_csr)\n",
    "\n",
    "    def recommend(users_list):\n",
    "        recs = {}\n",
    "        for u in users_list:\n",
    "            if u not in user_to_idx:\n",
    "                recs[u] = train_df[\"item_id\"].value_counts().index[:k].tolist()\n",
    "                continue\n",
    "            uid = user_to_idx[u]\n",
    "            recommended, scores = model.recommend(uid, user_item_csr[uid], N=k, filter_already_liked_items=True)\n",
    "            recs[u] = [items[i] for i in recommended]\n",
    "        return recs\n",
    "    return recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537d2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bootstrap(recommender, test_df, users, k=10, n_boot=20, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    scores_ndcg, scores_map = [], []\n",
    "    for _ in range(n_boot):\n",
    "        sampled_users = rng.choice(users, size=min(len(users), 500), replace=True)\n",
    "        recs = recommender(sampled_users)\n",
    "        ndcgs, maps = [], []\n",
    "        for u in sampled_users:\n",
    "            actual_items = test_df[(test_df[\"user_id\"]==u) & (test_df[\"rating\"]>0)][\"item_id\"].tolist()\n",
    "            predicted = recs[u]\n",
    "            r = [1 if i in actual_items else 0 for i in predicted]\n",
    "            ndcgs.append(ndcg_at_k(r, k))\n",
    "            maps.append(apk(actual_items, predicted, k))\n",
    "        scores_ndcg.append(np.mean(ndcgs))\n",
    "        scores_map.append(np.mean(maps))\n",
    "    return {\n",
    "        \"ndcg_mean\": np.mean(scores_ndcg),\n",
    "        \"ndcg_std\": np.std(scores_ndcg),\n",
    "        \"map_mean\": np.mean(scores_map),\n",
    "        \"map_std\": np.std(scores_map),\n",
    "        \"n_boot\": n_boot\n",
    "    }\n",
    "\n",
    "def print_results(name, res):\n",
    "    print(f\"{name}: nDCG@{K} = {res['ndcg_mean']:.4f} ± {res['ndcg_std']:.4f}, \"\n",
    "          f\"MAP@{K} = {res['map_mean']:.4f} ± {res['map_std']:.4f} (n_boot={res['n_boot']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c22e719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальные пользователи: 53424\n",
      "Уникальные айтемы: 10000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/ratings.csv\")\n",
    "data = data.rename(columns={'book_id': 'item_id'})\n",
    "data[\"user_id\"] = data[\"user_id\"].astype(str)\n",
    "data[\"item_id\"] = data[\"item_id\"].astype(str)\n",
    "data[\"rating\"] = data[\"rating\"].astype(int)\n",
    "\n",
    "if \"timestamp\" not in data.columns:\n",
    "    start_date = datetime(2021,1,1)\n",
    "    data[\"timestamp\"] = [start_date + timedelta(days=random.randint(0, 365*2)) for _ in range(len(data))]\n",
    "else:\n",
    "    data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], errors=\"coerce\")\n",
    "    mask = data[\"timestamp\"].isna()\n",
    "    if mask.any():\n",
    "        start_date = datetime(2021,1,1)\n",
    "        data.loc[mask, \"timestamp\"] = [start_date + timedelta(days=random.randint(0, 365*2)) for _ in range(mask.sum())]\n",
    "\n",
    "\n",
    "print(\"Уникальные пользователи:\", data[\"user_id\"].nunique())\n",
    "print(\"Уникальные айтемы:\", data[\"item_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38485cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_split(df, test_size=0.2):\n",
    "    train, test = [], []\n",
    "    for user_id in df['user_id'].unique():\n",
    "        user_data = df[df['user_id'] == user_id].sort_values('timestamp')\n",
    "        split_idx = int(len(user_data) * (1 - test_size))\n",
    "        train.append(user_data.iloc[:split_idx])\n",
    "        test.append(user_data.iloc[split_idx:])\n",
    "    return pd.concat(train), pd.concat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09617044",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_users = np.random.choice(data[\"user_id\"].unique(), size=SAMPLE_USERS, replace=False)\n",
    "data = data[data[\"user_id\"].isin(sample_users)].reset_index(drop=True)\n",
    "\n",
    "# Простые модели\n",
    "# train_simple, test_simple = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_simple, test_simple = temporal_split(data)\n",
    "\n",
    "# Сложные модели (time-based)\n",
    "data_sorted = data.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "split_idx = int(len(data_sorted) * 0.8)\n",
    "train_time = data_sorted.iloc[:split_idx].reset_index(drop=True)\n",
    "test_time  = data_sorted.iloc[split_idx:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6da3c642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: OpenBLAS is configured to use 20 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640fd0aa185b40f1bbb06832ca32c503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_items = data[\"item_id\"].unique()\n",
    "train_simple_ns = add_negative_samples(train_simple, all_items, negative_ratio=NEG_RATIO)\n",
    "test_simple_ns  = add_negative_samples(test_simple,  all_items, negative_ratio=NEG_RATIO)\n",
    "train_time_ns   = add_negative_samples(train_time,  all_items, negative_ratio=NEG_RATIO)\n",
    "test_time_ns    = add_negative_samples(test_time,   all_items, negative_ratio=NEG_RATIO)\n",
    "\n",
    "\n",
    "rec_random   = make_random_recommender(all_items, k=K)\n",
    "rec_pop      = make_popular_recommender(train_simple_ns, k=K)\n",
    "rec_pop_time = make_popular_time_recommender(train_time_ns, k=K, alpha=ALPHA_DECAY)\n",
    "rec_als      = make_als_recommender(train_time_ns, k=K, factors=32, reg=0.1, iters=15, seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76c73900",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_users_simple = test_simple_ns[\"user_id\"].unique()\n",
    "eval_users_time   = test_time_ns[\"user_id\"].unique()\n",
    "\n",
    "res_random   = evaluate_bootstrap(rec_random,   test_simple_ns, eval_users_simple, k=K, n_boot=N_BOOT)\n",
    "res_pop      = evaluate_bootstrap(rec_pop,      test_simple_ns, eval_users_simple, k=K, n_boot=N_BOOT)\n",
    "res_pop_time = evaluate_bootstrap(rec_pop_time, test_time_ns,   eval_users_time,   k=K, n_boot=N_BOOT)\n",
    "res_als      = evaluate_bootstrap(rec_als,      test_time_ns,   eval_users_time,   k=K, n_boot=N_BOOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfd72fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random: nDCG@10 = 0.0097 ± 0.0035, MAP@10 = 0.0006 ± 0.0003 (n_boot=20)\n",
      "Popular: nDCG@10 = 0.2420 ± 0.0161, MAP@10 = 0.0266 ± 0.0024 (n_boot=20)\n",
      "Popular+Time: nDCG@10 = 0.2237 ± 0.0125, MAP@10 = 0.0266 ± 0.0028 (n_boot=20)\n",
      "ALS(SVD): nDCG@10 = 0.6306 ± 0.0127, MAP@10 = 0.1766 ± 0.0102 (n_boot=20)\n"
     ]
    }
   ],
   "source": [
    "print_results(\"Random\", res_random)\n",
    "print_results(\"Popular\", res_pop)\n",
    "print_results(\"Popular+Time\", res_pop_time)\n",
    "print_results(\"ALS(SVD)\", res_als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8acf04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
